{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with Smote (resampling) Strategy\n",
    "#### Approach\n",
    "KNN approach is used for implementing recommendation system.\n",
    "However, the dataset has highly imbalanced data distribution. Supervised ML techniques such as KNN, Decision Tree, Logistic Regression  have a bias towards the majority class, and tend to ignore the minority class due to which they only predict majority class.\n",
    "There are two approaches followed to resolve this challenge, first on data level and second on algorithm level.\n",
    "1. On data level, resampling techniques were applied to get balanced distribution, like undersampling, Smote and Near-miss. Smote (synthetic minority oversampling technique) yielded better results with KNN out of all which is presented in the notebook wherein synthetic training records are generated.\n",
    "2. On algorithm level, hyperparameter selection and tuning was done along with threshold adjustments.\n",
    "\n",
    "#### Result\n",
    "After running several iterations of model and resampling strategies we obtained best results with KNN using Smote resampling and cosine metric.   \n",
    "**The best F1 score we achieved is 0.0536257482092042 (with 0.8 threshold).**\n",
    "\n",
    "Following is the code for the model used:\n",
    "\n",
    "## Part 1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from sklearn import neighbors, metrics\n",
    "\n",
    "# For Validation & Scaling\n",
    "from sklearn.preprocessing import StandardScaler # For scaling/standardizing dataset\n",
    "from sklearn.model_selection import train_test_split # Dataset Splitting\n",
    "from sklearn.model_selection import GridSearchCV # for Cross validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import f1_score # evaluation metrics\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install imbalanced-learn\n",
    "#conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pre-processed Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5950300, 25)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train = pd.read_csv(\"AkeedTrain.csv\")\n",
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop one ref categorical variable \n",
    "# 'cust_location_type_Other', 'gender_male','vendor_category_en_Sweets & Bakes','device_type_3',open hour na, \n",
    "X_Train = Train[['cust_location_type_Home', 'cust_location_type_Work', # dropped other\n",
    "               'gender_female', # dropped male\n",
    "               'delivery_charge','serving_distance', 'is_open', 'prepration_time','discount_percentage',\n",
    "               'ven_status', 'ven_verified','vendor_rating', 'Ven_created_days', \n",
    "               'TotOpenDuration',\n",
    "               'vendor_category_en_Restaurants', # dropped Sweets & Bakes\n",
    "               'device_type_1', # dropped device_type_3 \n",
    "               'timegroup_early(5-10.59am)','timegroup_normal(11-16.59pm)','timegroup_evening(17-22.59pm)','timegroup_latenight(23-4.59am)']] # dropped na\n",
    "y_Train = Train['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library for Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "# print(imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5870158, 1: 80142})\n"
     ]
    }
   ],
   "source": [
    "# find classes\n",
    "counter = Counter(y_Train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5870158, 1: 5870158})\n"
     ]
    }
   ],
   "source": [
    "# Balance classes\n",
    "oversample = SMOTE()\n",
    "x_trSM, y_trSM = oversample.fit_resample(X_Train, y_Train)\n",
    "counter = Counter(y_trSM)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "Create a holdout set from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create  % split as train-test split of original data\n",
    "X_training, X_testing, y_training, y_testing = train_test_split(x_trSM, y_trSM, test_size=0.95, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline to run KNN with Hyperparameter tuning and 5 fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time in mins: 644.6616194923719\n",
      "Best hyper parameter set : {'knn_clf__n_neighbors': 9, 'knn_clf__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#    ******** Method: KNN ******** \n",
    "start = time.time() # record start time\n",
    "# 1. Set up the model pipeline\n",
    "estimator = Pipeline(steps = [('scale', StandardScaler()), # Scale the data\n",
    "                     ('knn_clf', neighbors.KNeighborsClassifier(metric = 'cosine', algorithm = 'brute')) ]) # fit the scaled data using KNN\n",
    "\n",
    "# 2. Set up the parameters for each item in pipeline\n",
    "parameters = { 'knn_clf__n_neighbors':range(4,10),'knn_clf__weights' : ['uniform','distance']}\n",
    "\n",
    "# 3. Instantiate gridsearch cross validation for the model in pipeline\n",
    "knn = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 5, \n",
    "                   scoring = 'f1', n_jobs = -2) # Instantiate the gridsearch\n",
    "\n",
    "# 4. fit the model on train data\n",
    "knn.fit(X_training, y_training)\n",
    "end = time.time() # record end time\n",
    "print('Tuning time in mins:',(end-start)/60)\n",
    "\n",
    "print('Best hyper parameter set :',knn.best_params_)   # The best parameter from CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score of KNN on test set: 0.5941698847682907\n",
      "predict time in mins: 2063.160816880067\n"
     ]
    }
   ],
   "source": [
    "# 5. evaluation on test set and f1 score with 0.5 threshold\n",
    "start = time.time()\n",
    "print('f1 score of KNN on test set:',f1_score(y_testing,knn.predict(X_testing)))\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Threshold maximizing F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. find best threshold on test set \n",
    "thresholds = np.linspace(0, 1, 20) # Set up threshold values\n",
    "f1 = []\n",
    "for a in thresholds:\n",
    "    yhat = np.where(knn.predict_proba(X_testing)[:,1] > a, 1,0)\n",
    "    #conf_matrix = confusion_matrix(y_testing, yhat, labels=[1,0])\n",
    "    TP = conf_matrix[0,0]\n",
    "    FN = conf_matrix[0,1]\n",
    "    FP = conf_matrix[1,0]\n",
    "    TN = conf_matrix[1,1]\n",
    "\n",
    "    P = TP/(TP+FP)\n",
    "    R = TP/(TP+FN)\n",
    "\n",
    "    f1_score = 2/((1/P)+(1/R))\n",
    "    f1.append(f1_score)\n",
    "\n",
    "# Find the threshold with the best f1\n",
    "best_a = thresholds[np.argmax(f1)]\n",
    "print(best_a)\n",
    "print(f1[np.argmax(fo)])\n",
    "\n",
    "# Evaluate on the test set\n",
    "yhat = np.where(knn.predict_proba(X_testing)[:,1] > best_a, 1,0)\n",
    "conf_matrix1 = confusion_matrix(y_testing, yhat, labels=[1,0])\n",
    "print(conf_matrix1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672000, 97)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test pre-processed test dataset in the required format\n",
    "Test = pd.read_csv(\"test\\cust_ven_test_p2.csv\")\n",
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Reference column for KNN\n",
    "X_Test = Test[['cust_location_type_Home', 'cust_location_type_Work', # dropped other\n",
    "               'gender_female', # dropped male\n",
    "               'delivery_charge','serving_distance', 'is_open', 'prepration_time','discount_percentage',\n",
    "               'ven_status', 'ven_verified','vendor_rating', 'Ven_created_days', \n",
    "               'TotOpenDuration',\n",
    "               'vendor_category_en_Restaurants', # dropped Sweets & Bakes\n",
    "               'device_type_1', # dropped device_type_3 \n",
    "               'timegroup_early(5-10.59am)','timegroup_normal(11-16.59pm)','timegroup_evening(17-22.59pm)','timegroup_latenight(23-4.59am)']] # dropped na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test set with multiple threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "predict time in mins: 304.6312898437182\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_hat_Test_def = np.where(knn.predict_proba(X_Test)[:,1] > 0.5, 1, 0)\n",
    "print(y_hat_Test_def)\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 0 0]\n",
      "predict time in mins: 310.82710293928784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "y_hat_Test_def4 = np.where(knn.predict_proba(X_Test)[:,1] > 0.4, 1, 0)\n",
    "print(y_hat_Test_def4)\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "predict time in mins: 300.16979573965074\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "y_hat_Test_def6 = np.where(knn.predict_proba(X_Test)[:,1] > 0.6, 1, 0)\n",
    "print(y_hat_Test_def6)\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "predict time in mins: 304.1332718451818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "y_hat_Test_def7 = np.where(knn.predict_proba(X_Test)[:,1] > 0.7, 1, 0)\n",
    "print(y_hat_Test_def7)\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "predict time in mins: 308.41722063620887\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "y_hat_Test_def8 = np.where(knn.predict_proba(X_Test)[:,1] > 0.8, 1, 0)\n",
    "print(y_hat_Test_def8)\n",
    "end = time.time() # record end time\n",
    "print('predict time in mins:',(end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_CID X LOC_NUM X VENDOR</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000IPH5 X 0 X 4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000IPH5 X 0 X 13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000IPH5 X 0 X 20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000IPH5 X 0 X 23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000IPH5 X 0 X 28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671995</td>\n",
       "      <td>G49BIQ7 X 0 X 849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671996</td>\n",
       "      <td>G49BIQ7 X 0 X 855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671997</td>\n",
       "      <td>G49BIQ7 X 0 X 856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671998</td>\n",
       "      <td>G49BIQ7 X 0 X 858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1671999</td>\n",
       "      <td>G49BIQ7 X 0 X 907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1672000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        test_CID X LOC_NUM X VENDOR  yhat\n",
       "0                   000IPH5 X 0 X 4     1\n",
       "1                  000IPH5 X 0 X 13     0\n",
       "2                  000IPH5 X 0 X 20     0\n",
       "3                  000IPH5 X 0 X 23     1\n",
       "4                  000IPH5 X 0 X 28     1\n",
       "...                             ...   ...\n",
       "1671995           G49BIQ7 X 0 X 849     1\n",
       "1671996           G49BIQ7 X 0 X 855     0\n",
       "1671997           G49BIQ7 X 0 X 856     0\n",
       "1671998           G49BIQ7 X 0 X 858     0\n",
       "1671999           G49BIQ7 X 0 X 907     0\n",
       "\n",
       "[1672000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test_SS = pd.DataFrame({'test_CID X LOC_NUM X VENDOR':Test['test_CID X LOC_NUM X VENDOR'],'yhat':pd.Series(y_hat_Test_def)})\n",
    "df_Test_SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesubmission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.merge(samplesubmission,df_Test_SS,\n",
    "                   left_on='CID X LOC_NUM X VENDOR', right_on='test_CID X LOC_NUM X VENDOR',how='left')\n",
    "print(compare_df.shape)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Test_SS.columns = ['CID X LOC_NUM X VENDOR','target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the csv in the requested format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_SS.to_csv('KNN cosine SMOTE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_SS1 = pd.DataFrame({'test_CID X LOC_NUM X VENDOR':Test['test_CID X LOC_NUM X VENDOR'],'yhat':pd.Series(y_hat_Test_def4)})\n",
    "df_Test_SS1.columns = ['CID X LOC_NUM X VENDOR','target']\n",
    "df_Test_SS1.to_csv('KNN cosine SMOTE 4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_SS2 = pd.DataFrame({'test_CID X LOC_NUM X VENDOR':Test['test_CID X LOC_NUM X VENDOR'],'yhat':pd.Series(y_hat_Test_def6)})\n",
    "df_Test_SS2.columns = ['CID X LOC_NUM X VENDOR','target']\n",
    "df_Test_SS2.to_csv('KNN cosine SMOTE 6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_SS3 = pd.DataFrame({'test_CID X LOC_NUM X VENDOR':Test['test_CID X LOC_NUM X VENDOR'],'yhat':pd.Series(y_hat_Test_def7)})\n",
    "df_Test_SS3.columns = ['CID X LOC_NUM X VENDOR','target']\n",
    "df_Test_SS3.to_csv('KNN cosine SMOTE 7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test_SS4 = pd.DataFrame({'test_CID X LOC_NUM X VENDOR':Test['test_CID X LOC_NUM X VENDOR'],'yhat':pd.Series(y_hat_Test_def8)})\n",
    "df_Test_SS4.columns = ['CID X LOC_NUM X VENDOR','target']\n",
    "df_Test_SS4.to_csv('KNN cosine SMOTE 8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
